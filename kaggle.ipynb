{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK:\n",
    "Improve test score to 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/whats-cooking-kernels-only/data\n",
    "# https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39774, 3), (9944, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train_df = pd.read_json('all/train.json')\n",
    "test_df = pd.read_json('all/test.json')\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'cuisine', u'id', u'ingredients'], dtype='object'),\n",
       " Index([u'id', u'ingredients'], dtype='object'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuisine        0\n",
      "id             0\n",
      "ingredients    0\n",
      "dtype: int64\n",
      "id             0\n",
      "ingredients    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect  missing values\n",
    "print(train_df.isna().sum())\n",
    "print(test_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible issues:\n",
    "# multiple ID\n",
    "# spelling mistakes\n",
    "# spelling case\n",
    "# ingredients multiple times\n",
    "# singular / plural\n",
    "# different names for same ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italian         7838\n",
       "mexican         6438\n",
       "southern_us     4320\n",
       "indian          3003\n",
       "chinese         2673\n",
       "french          2646\n",
       "cajun_creole    1546\n",
       "thai            1539\n",
       "japanese        1423\n",
       "greek           1175\n",
       "spanish          989\n",
       "korean           830\n",
       "vietnamese       825\n",
       "moroccan         821\n",
       "british          804\n",
       "filipino         755\n",
       "irish            667\n",
       "jamaican         526\n",
       "russian          489\n",
       "brazilian        467\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cuisine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# ML pipeline consisting of two steps\n",
    "pipeline = Pipeline(steps=[\n",
    "    \n",
    "    ('tdidf', TfidfVectorizer()),\n",
    "    ('SVC', SVC(C=100, # penalty parameter\n",
    "\t \t\t\t kernel='rbf', # kernel type, rbf working fine here\n",
    "\t \t\t\t degree=3, # default value\n",
    "\t \t\t\t gamma=1, # kernel coefficient\n",
    "\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n",
    "\t \t\t\t shrinking=True, # using shrinking heuristics\n",
    "\t \t\t\t tol=0.001, # stopping criterion tolerance \n",
    "\t      \t\t probability=False, # no need to enable probability estimates\n",
    "\t      \t\t cache_size=600, # 200 MB cache size\n",
    "\t      \t\t class_weight=None, # all classes are treated equally \n",
    "# \t      \t\t verbose=False, # print the logs \n",
    "# \t      \t\t max_iter=-1, # no limit, let it run\n",
    "#           \t\t decision_function_shape=None, # will use one vs rest explicitly \n",
    "#           \t\t random_state=None\n",
    "               )),\n",
    "#     ('RFC', RandomForestClassifier(n_estimators= 100)),\n",
    "#     ('LR', LogisticRegression()),\n",
    "#     ('GB', GradientBoostingClassifier()),\n",
    "#     ('GBC', KNeighborsClassifier(n_neighbors=100)),\n",
    "])\n",
    "pipeline = OneVsRestClassifier(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romaine_lettuce black_olives grape\n"
     ]
    }
   ],
   "source": [
    "list_ing = ['romaine lettuce', 'black olives', 'grape']\n",
    "\n",
    "def func(l):\n",
    "    string = \"/\".join(l)\n",
    "    result = string.replace(\" \",\"_\")\n",
    "    result2 = result.replace(\"/\",\" \")    \n",
    "    return result2\n",
    "print func(list_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_cols = ['ingredients']\n",
    "y_cols = ['cuisine']\n",
    "\n",
    "x = train_df.filter(items=x_cols)['ingredients'].apply(func)# turn list of strings into one string\n",
    "y = train_df.filter(items=y_cols).values.ravel()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, test_size=0.3)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCORE: \n",
      "0.9995689809992457\n",
      "TEST SCORE: \n",
      "0.8037375345680047\n",
      "CPU times: user 17min 32s, sys: 6.67 s, total: 17min 39s\n",
      "Wall time: 17min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(x_train, y_train)\n",
    "print (\"TRAIN SCORE: \")\n",
    "print(pipeline.score(x_train, y_train))\n",
    "print (\"TEST SCORE: \")\n",
    "print(pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(pipeline, x, y, cv=3, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# for train_sizes, train_scores, test_scores in learning_curve(pipeline, x, y, cv=5):\n",
    "#     print (train_sizes, train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
